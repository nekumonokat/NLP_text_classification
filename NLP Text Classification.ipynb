{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d423c27a",
   "metadata": {},
   "source": [
    "<h2><center>NLP Text Classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfae6d7",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e57e3",
   "metadata": {},
   "source": [
    "### 1.1 Domain-specific area\n",
    "This project provides an analysis of textual data on Twitter to accurately detect and classify threatening or harmful content using sentiment analysis techniques. This would provide the cybersecurity industry a tool that takes in a corpus of text for training to develop a strong detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94927ae8",
   "metadata": {},
   "source": [
    "### 1.2 Objectives\n",
    "Due to popular algorithms being centered around the detection of cyberbullying on social media (Cynthia Van Hee et al., 2018), it is important for this project to widen the scope of detection. While the general detection algorithms focus mainly on terrorism and cyberbullying, it is a known fact that cybersecurity encompasses more than those 2 focuses. (Khairy, Mahmoud and Abd-El-Hafeez, 2021) While full security and safety of users cannot be ensured, making these adjustments would contribute valuable insights for future development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58258782",
   "metadata": {},
   "source": [
    "### 1.3 Dataframe\n",
    "To begin this project, an extensive amount of textual data corpora is required. After researching large dataframes of Tweets, Sentiment140 Kaggle was proven to be the best for this project. With 1.6 million tweets extracted using the Twitter API, the authors have categorised each tweet to have either a positive, neutral or negative sentiment, which is beneficial for the algorithm in categorising harmful texts.\n",
    "\n",
    "The dataframe consists of the target (defined as the sentiment of the text), the tweet IDs, date, flags (possible queries, which would be removed in the initialisation phase of extracting the data), the username, and the text of the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55178994",
   "metadata": {},
   "source": [
    "### 1.4 Evaluation methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fac88e",
   "metadata": {},
   "source": [
    "## II. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123224ba",
   "metadata": {},
   "source": [
    "### 2.1 Pre-processing\n",
    "(writeup not needed)\n",
    "<br>Convert/store the dataframe locally and preprocess the data. Describe the text representation\n",
    "(e.g., bag of words, word embedding, etc.) and any pre-processing steps you have applied\n",
    "and why they were needed (e.g. tokenization, lemmatization). Describe the vocabulary and\n",
    "file type/format, e.g. CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71c46e",
   "metadata": {},
   "source": [
    "#### Acquiring dataframe\n",
    "The dataframe on the collection of Tweets were acquired from Kaggle by downloading the CSV file. The author of this dataframe is Μαριος Μιχαηλιδης KazAnova. The code for importing the dataframe is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec63c56",
   "metadata": {},
   "source": [
    "#### 2.1.1 Importing libraries\n",
    "- <b>pandas library</b> was imported to process and handle dataframes in Python. It is used to help write and read from CSV files while handling real-world messy data and processing them into a proper format\n",
    "\n",
    "- <b>numpy library</b> was imported to handle calculations and use numpy arrays for statistical calculations\n",
    "\n",
    "- <b>matplotlib library</b> was imported to plot the data and represent it graphically\n",
    "\n",
    "- <b>os library</b> was imported to have a way of using the operating system dependent functionalities, more specifically to save the dataframe as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38604c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb791d",
   "metadata": {},
   "source": [
    "#### 2.1.2 Creating helper functions\n",
    "- <b>displaysetsH</b> takes in a list of dataframes and an optional number of rows to display the head of each dataframe\n",
    "\n",
    "- <b>displaysetsT</b> takes in a list of dataframes and an optional number of rows to display the tail of each dataframe\n",
    "\n",
    "- <b>resetidx</b> takes in a list of dataframes to reset the indexes of each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d4f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaysetsH(dataframes, amt = 5):\n",
    "    for dataframe in dataframes:\n",
    "        display(dataframe.head(amt))\n",
    "        \n",
    "def displaysetsT(dataframes, amt = 5):\n",
    "    for dataframe in dataframes:\n",
    "        display(dataframe.head(amt))\n",
    "        \n",
    "def resetidx(dataframes):\n",
    "    for dataframe in dataframes:\n",
    "        dataframe.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a48e8",
   "metadata": {},
   "source": [
    "#### 2.1.3 Importing dataframe\n",
    "Due to the dataframe being too large for analysis, we will analyse the first 1000 textual data corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12a3c11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055266</td>\n",
       "      <td>Mon Apr 06 23:28:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ohmigosh_dusti</td>\n",
       "      <td>@t_wolfe  i miss u too. i'm totally comin back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055472</td>\n",
       "      <td>Mon Apr 06 23:28:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tiphaniebrooke</td>\n",
       "      <td>@sniffinglue ohhh. I love it. ps I'm sad we di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055604</td>\n",
       "      <td>Mon Apr 06 23:28:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>rinahannah</td>\n",
       "      <td>And somehow I still end up in this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055791</td>\n",
       "      <td>Mon Apr 06 23:28:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ecjc</td>\n",
       "      <td>@kisluvkis oh that is very sad, poor boy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055852</td>\n",
       "      <td>Mon Apr 06 23:28:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Saphyre1969</td>\n",
       "      <td>@JonathanRKnight @silver_tulip27 Um, that woul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0    0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1    0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2    0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3    0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4    0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "..  ..         ...                           ...       ...             ...   \n",
       "995  0  1468055266  Mon Apr 06 23:28:41 PDT 2009  NO_QUERY  ohmigosh_dusti   \n",
       "996  0  1468055472  Mon Apr 06 23:28:43 PDT 2009  NO_QUERY  tiphaniebrooke   \n",
       "997  0  1468055604  Mon Apr 06 23:28:45 PDT 2009  NO_QUERY      rinahannah   \n",
       "998  0  1468055791  Mon Apr 06 23:28:49 PDT 2009  NO_QUERY            ecjc   \n",
       "999  0  1468055852  Mon Apr 06 23:28:50 PDT 2009  NO_QUERY     Saphyre1969   \n",
       "\n",
       "    @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0    is upset that he can't update his Facebook by ...                                                                   \n",
       "1    @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2      my whole body feels itchy and like its on fire                                                                    \n",
       "3    @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                        @Kwesidei not the whole crew                                                                    \n",
       "..                                                 ...                                                                   \n",
       "995  @t_wolfe  i miss u too. i'm totally comin back...                                                                   \n",
       "996  @sniffinglue ohhh. I love it. ps I'm sad we di...                                                                   \n",
       "997          And somehow I still end up in this place                                                                    \n",
       "998         @kisluvkis oh that is very sad, poor boy.                                                                    \n",
       "999  @JonathanRKnight @silver_tulip27 Um, that woul...                                                                   \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/sentiment140_dataset.csv\", nrows = 1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c3a61a",
   "metadata": {},
   "source": [
    "#### 2.1.4 Adding headers\n",
    "Based on analysing tweets_df.head(), it is seen that the dataframe does not have any headers. As such, the first process would be to add the headers to aid in future analysis. The columns 'tweet_id', 'date', 'flag' and 'user' will then be removed as the project focus is on the sentiment analysis. This modified dataframe will then be stored as a new CSV file.\n",
    "\n",
    "(<i>the headers are modified based on looking at the contents from Kaggle</i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "45cd75e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>@dkoenigs thanks man.  I'm so very grateful.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>@t_wolfe  i miss u too. i'm totally comin back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>@sniffinglue ohhh. I love it. ps I'm sad we di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>And somehow I still end up in this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>@kisluvkis oh that is very sad, poor boy.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                              tweet\n",
       "0            0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1            0  is upset that he can't update his Facebook by ...\n",
       "2            0  @Kenichan I dived many times for the ball. Man...\n",
       "3            0    my whole body feels itchy and like its on fire \n",
       "4            0  @nationwideclass no, it's not behaving at all....\n",
       "..         ...                                                ...\n",
       "995          0  @dkoenigs thanks man.  I'm so very grateful.  ...\n",
       "996          0  @t_wolfe  i miss u too. i'm totally comin back...\n",
       "997          0  @sniffinglue ohhh. I love it. ps I'm sad we di...\n",
       "998          0          And somehow I still end up in this place \n",
       "999          0         @kisluvkis oh that is very sad, poor boy. \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['sentiment', 'tweet_id', 'date', 'flag', 'user', 'tweet']\n",
    "tweets_df = pd.read_csv(\"dataframes/sentiment140_dataframe.csv\", nrows = 1000, names = headers)\n",
    "columns_to_drop = ['tweet_id', 'date', 'flag', 'user']\n",
    "tweets_df.drop(columns = columns_to_drop, inplace = True)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1fd1d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'datasets/expanded_sentiment140_dataframe.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    tweets_df.to_csv(file_path, index = False)\n",
    "    print('File saved successfully.')\n",
    "else:\n",
    "    print('File already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005bbd1",
   "metadata": {},
   "source": [
    "### 2.2 Baseline performance\n",
    "(writeup not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7d00e",
   "metadata": {},
   "source": [
    "### 2.3 Classification approach\n",
    "(writeup not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba01907",
   "metadata": {},
   "source": [
    "### 2.4 Coding style\n",
    "(writeup not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693ad19",
   "metadata": {},
   "source": [
    "## III. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab58e4",
   "metadata": {},
   "source": [
    "### 3.1 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad60e03",
   "metadata": {},
   "source": [
    "### 3.2 Summary and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b277005",
   "metadata": {},
   "source": [
    "## Temporary reference list\n",
    "* to use citation generator\n",
    "\n",
    "- Cynthia Van Hee, Jacobs, G., Emmery, C., Desmet, B., Lefever, E., Verhoeven, B., Guy De Pauw, Daelemans, W. and Hoste, V. (2018). Automatic detection of cyberbullying in social media text. PLOS ONE, [online] 13(10), p.e0203794. doi:https://doi.org/10.1371/journal.pone.0203794.\n",
    "- Khairy, M., Mahmoud, T.M. and Abd-El-Hafeez, T. (2021). Automatic Detection of Cyberbullying and Abusive Language in Arabic Content on Social Networks: A Survey. Procedia Computer Science, [online] 189, pp.156–166. doi:https://doi.org/10.1016/j.procs.2021.05.080."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
