{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d423c27a",
   "metadata": {},
   "source": [
    "<h2><center>NLP Text Classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d0067",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101e842",
   "metadata": {},
   "source": [
    "### 1.1 Domain-specific area\n",
    "This project provides an analysis of textual data on Twitter to accurately detect and classify threatening or harmful content using sentiment analysis techniques. This would provide the cybersecurity industry a tool that takes in a corpus of text for training to develop a strong detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72286743",
   "metadata": {},
   "source": [
    "### 1.2 Objectives\n",
    "Due to popular algorithms being centered around the detection of cyberbullying on social media (Cynthia Van Hee et al., 2018), it is important for this project to widen the scope of detection. While the general detection algorithms focus mainly on terrorism and cyberbullying, it is a known fact that cybersecurity encompasses more than those 2 focuses. (Khairy, Mahmoud and Abd-El-Hafeez, 2021) While full security and safety of users cannot be ensured, making these adjustments would contribute valuable insights for future development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd0cf1",
   "metadata": {},
   "source": [
    "### 1.3 Dataset\n",
    "To begin this project, an extensive amount of textual data corpora is required. After researching large datasets of Tweets, Sentiment140 Kaggle was proven to be the best for this project. With 1.6 million tweets extracted using the Twitter API, the authors have categorised each tweet to have either a positive, neutral or negative sentiment, which is beneficial for the algorithm in categorising harmful texts.\n",
    "\n",
    "The dataset consists of the target (defined as the sentiment of the text), the tweet IDs, date, flags (possible queries, which would be removed in the initialisation phase of extracting the data), the username, and the text of the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f381e0e6",
   "metadata": {},
   "source": [
    "### 1.4 Evaluation methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d3b22",
   "metadata": {},
   "source": [
    "## II. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8e1df4",
   "metadata": {},
   "source": [
    "### 2.1 Pre-processing\n",
    "(writeup not needed)\n",
    "<br>Convert/store the dataset locally and preprocess the data. Describe the text representation\n",
    "(e.g., bag of words, word embedding, etc.) and any pre-processing steps you have applied\n",
    "and why they were needed (e.g. tokenization, lemmatization). Describe the vocabulary and\n",
    "file type/format, e.g. CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38466cb4",
   "metadata": {},
   "source": [
    "#### Acquiring dataset\n",
    "The dataset on the collection of Tweets were acquired from Kaggle by downloading the CSV file. The author of this dataset is Μαριος Μιχαηλιδης KazAnova. The code for importing the dataset is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641807df",
   "metadata": {},
   "source": [
    "#### 2.1.1 Importing libraries\n",
    "- <b>pandas library</b> was imported to process and handle datasets in Python. It is used to help write and read from CSV files while handling real-world messy data and processing them into a proper format\n",
    "\n",
    "- <b>numpy library</b> was imported to handle calculations and use numpy arrays for statistical calculations\n",
    "\n",
    "- <b>matplotlib library</b> was imported to plot the data and represent it graphically\n",
    "\n",
    "- <b>os library</b> was imported to have a way of using the operating system dependent functionalities, more specifically to save the dataset as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26cf64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aacc76",
   "metadata": {},
   "source": [
    "#### 2.1.2 Creating helper functions\n",
    "- <b>displaysetsH</b> takes in a list of datasets and an optional number of rows to display the head of each dataset\n",
    "\n",
    "- <b>displaysetsT</b> takes in a list of datasets and an optional number of rows to display the tail of each dataset\n",
    "\n",
    "- <b>resetidx</b> takes in a list of datasets to reset the indexes of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9075d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaysetsH(datasets, amt = 5):\n",
    "    for dataset in datasets:\n",
    "        display(dataset.head(amt))\n",
    "        \n",
    "def displaysetsT(datasets, amt = 5):\n",
    "    for dataset in datasets:\n",
    "        display(dataset.head(amt))\n",
    "        \n",
    "def resetidx(datasets):\n",
    "    for dataset in datasets:\n",
    "        dataset.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39c4f8",
   "metadata": {},
   "source": [
    "#### 2.1.3 Importing dataset\n",
    "Due to the dataset being too large for analysis, we will analyse the first 1000 textual data corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98626b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055266</td>\n",
       "      <td>Mon Apr 06 23:28:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ohmigosh_dusti</td>\n",
       "      <td>@t_wolfe  i miss u too. i'm totally comin back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055472</td>\n",
       "      <td>Mon Apr 06 23:28:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tiphaniebrooke</td>\n",
       "      <td>@sniffinglue ohhh. I love it. ps I'm sad we di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055604</td>\n",
       "      <td>Mon Apr 06 23:28:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>rinahannah</td>\n",
       "      <td>And somehow I still end up in this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055791</td>\n",
       "      <td>Mon Apr 06 23:28:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ecjc</td>\n",
       "      <td>@kisluvkis oh that is very sad, poor boy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>1468055852</td>\n",
       "      <td>Mon Apr 06 23:28:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Saphyre1969</td>\n",
       "      <td>@JonathanRKnight @silver_tulip27 Um, that woul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0    0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1    0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2    0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3    0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4    0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "..  ..         ...                           ...       ...             ...   \n",
       "995  0  1468055266  Mon Apr 06 23:28:41 PDT 2009  NO_QUERY  ohmigosh_dusti   \n",
       "996  0  1468055472  Mon Apr 06 23:28:43 PDT 2009  NO_QUERY  tiphaniebrooke   \n",
       "997  0  1468055604  Mon Apr 06 23:28:45 PDT 2009  NO_QUERY      rinahannah   \n",
       "998  0  1468055791  Mon Apr 06 23:28:49 PDT 2009  NO_QUERY            ecjc   \n",
       "999  0  1468055852  Mon Apr 06 23:28:50 PDT 2009  NO_QUERY     Saphyre1969   \n",
       "\n",
       "    @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0    is upset that he can't update his Facebook by ...                                                                   \n",
       "1    @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2      my whole body feels itchy and like its on fire                                                                    \n",
       "3    @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                        @Kwesidei not the whole crew                                                                    \n",
       "..                                                 ...                                                                   \n",
       "995  @t_wolfe  i miss u too. i'm totally comin back...                                                                   \n",
       "996  @sniffinglue ohhh. I love it. ps I'm sad we di...                                                                   \n",
       "997          And somehow I still end up in this place                                                                    \n",
       "998         @kisluvkis oh that is very sad, poor boy.                                                                    \n",
       "999  @JonathanRKnight @silver_tulip27 Um, that woul...                                                                   \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/sentiment140_dataset.csv\", nrows = 1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f3823",
   "metadata": {},
   "source": [
    "#### 2.1.4 Adding headers\n",
    "Based on analysing tweets_df.head(), it is seen that the dataset does not have any headers. As such, the first process would be to add the headers to aid in future analysis. The columns 'tweet_id', 'date', 'flag' and 'user' will then be removed as the project focus is on the sentiment analysis. This modified dataset will then be stored as a new CSV file.\n",
    "\n",
    "(<i>the headers are modified based on looking at the contents from Kaggle</i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ae8791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>@dkoenigs thanks man.  I'm so very grateful.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>@t_wolfe  i miss u too. i'm totally comin back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>@sniffinglue ohhh. I love it. ps I'm sad we di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>And somehow I still end up in this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>@kisluvkis oh that is very sad, poor boy.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                              tweet\n",
       "0            0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1            0  is upset that he can't update his Facebook by ...\n",
       "2            0  @Kenichan I dived many times for the ball. Man...\n",
       "3            0    my whole body feels itchy and like its on fire \n",
       "4            0  @nationwideclass no, it's not behaving at all....\n",
       "..         ...                                                ...\n",
       "995          0  @dkoenigs thanks man.  I'm so very grateful.  ...\n",
       "996          0  @t_wolfe  i miss u too. i'm totally comin back...\n",
       "997          0  @sniffinglue ohhh. I love it. ps I'm sad we di...\n",
       "998          0          And somehow I still end up in this place \n",
       "999          0         @kisluvkis oh that is very sad, poor boy. \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['sentiment', 'tweet_id', 'date', 'flag', 'user', 'tweet']\n",
    "tweets_df = pd.read_csv(\"datasets/sentiment140_dataset.csv\", nrows = 1000, names = headers)\n",
    "columns_to_drop = ['tweet_id', 'date', 'flag', 'user']\n",
    "tweets_df.drop(columns = columns_to_drop, inplace = True)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e132cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'datasets/expanded_sentiment140_dataset.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    tweets_df.to_csv(file_path, index = False)\n",
    "    print('File saved successfully.')\n",
    "else:\n",
    "    print('File already exists.')\n",
    "   \n",
    "tweets_df = pd.read_csv(\"datasets/expanded_sentiment140_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6e51f",
   "metadata": {},
   "source": [
    "#### 2.1.5 Checking for duplicates and null entries\n",
    "To ensure that the analysis is beneficial, all 1000 entries that were chosen should be unique. To do so, a 'duplicated' column will be added to the a temporary copy of the dataset which is the output of df.duplicated() and we will print only columns where the 'duplicated' column is True.\n",
    "\n",
    "Based on the output, it is seen that there are no duplicated Tweets.\n",
    "\n",
    "After ensuring that all entries are unique, a check that all entries do not have NULL entries will be done. This is because sentiment analysis cannot be done on empty texts.\n",
    "\n",
    "Based on the output, it is seen that there are no NULL entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b88b7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>duplicated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment, tweet, duplicated]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_checker = tweets_df.copy()\n",
    "duplicates = dupe_checker.duplicated()\n",
    "dupe_checker['duplicated'] = duplicates\n",
    "duplicated = dupe_checker[dupe_checker['duplicated'] == True]\n",
    "duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50595fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "tweet        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_checker = tweets_df.copy()\n",
    "null_checker.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44983f22",
   "metadata": {},
   "source": [
    "#### 2.1.6 Basic statistics\n",
    "To ensure that the data is good for analysis, the amount of positive, neutral and negative sentiments should be as balanced as possible\n",
    "\n",
    "(0 = negative, 2 = neutral, 4 = positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f86dd81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive sentiments: sentiment    0\n",
      "tweet        0\n",
      "dtype: int64\n",
      "Number of neutral sentiments: sentiment    0\n",
      "tweet        0\n",
      "dtype: int64\n",
      "Number of negative sentiments: sentiment    1000\n",
      "tweet        1000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "temp = tweets_df.copy()\n",
    "print(\"Number of positive sentiments:\", temp[temp['sentiment'] == 4].count())\n",
    "print(\"Number of neutral sentiments:\", temp[temp['sentiment'] == 2].count())\n",
    "print(\"Number of negative sentiments:\", temp[temp['sentiment'] == 0].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2fd548",
   "metadata": {},
   "source": [
    "### 2.2 Baseline performance\n",
    "(writeup not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ca830",
   "metadata": {},
   "source": [
    "### 2.3 Classification approach\n",
    "(writeup not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0d9cc",
   "metadata": {},
   "source": [
    "### 2.4 Coding style\n",
    "(writeup not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c187d",
   "metadata": {},
   "source": [
    "## III. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c2562",
   "metadata": {},
   "source": [
    "### 3.1 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e3055",
   "metadata": {},
   "source": [
    "### 3.2 Summary and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950434fd",
   "metadata": {},
   "source": [
    "## Temporary reference list\n",
    "* to use citation generator\n",
    "\n",
    "- Cynthia Van Hee, Jacobs, G., Emmery, C., Desmet, B., Lefever, E., Verhoeven, B., Guy De Pauw, Daelemans, W. and Hoste, V. (2018). Automatic detection of cyberbullying in social media text. PLOS ONE, [online] 13(10), p.e0203794. doi:https://doi.org/10.1371/journal.pone.0203794.\n",
    "- Khairy, M., Mahmoud, T.M. and Abd-El-Hafeez, T. (2021). Automatic Detection of Cyberbullying and Abusive Language in Arabic Content on Social Networks: A Survey. Procedia Computer Science, [online] 189, pp.156–166. doi:https://doi.org/10.1016/j.procs.2021.05.080."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
